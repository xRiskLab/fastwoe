{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastWoe v0.1.6a - CAP Curve with Weighted Gini\n",
    "\n",
    "Demonstrates:\n",
    "\n",
    "- Weighted Gini coefficient for binary classification\n",
    "- Multiple model comparison on same plot\n",
    "- Custom colormap support\n",
    "- Flexible grid layouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fastwoe.metrics import plot_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Credit Risk Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "n = 10000\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"age\": np.random.randint(18, 75, n),\n",
    "        \"income\": np.random.lognormal(10.5, 0.8, n),\n",
    "        \"credit_score\": np.random.randint(300, 850, n),\n",
    "        \"debt_to_income\": np.random.uniform(0, 1.5, n),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Binary target (default indicator)\n",
    "default_prob = 1 / (\n",
    "    1\n",
    "    + np.exp(\n",
    "        5\n",
    "        - 0.01 * (df[\"credit_score\"] - 500)\n",
    "        - 0.5 * np.log(df[\"income\"] / 30000)\n",
    "        + 2 * df[\"debt_to_income\"]\n",
    "    )\n",
    ")\n",
    "y = np.random.binomial(1, default_prob)\n",
    "\n",
    "# Exposure at Default (EAD weights)\n",
    "ead = np.random.lognormal(10, 1.5, n)\n",
    "\n",
    "print(f\"Dataset: {n:,} samples\")\n",
    "print(f\"Default rate: {y.mean():.2%}\")\n",
    "print(f\"Total EAD: ${ead.sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Multiple Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test, ead_train, ead_test = train_test_split(\n",
    "    df, y, ead, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train 3 different models\n",
    "models = {\n",
    "    \"Logistic\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions[name] = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"✓ {name} trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Model - Unweighted Gini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, gini = plot_performance(y_true=y_test, y_pred=predictions[\"Logistic\"])\n",
    "\n",
    "print(f\"Gini (unweighted): {gini:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single Model - EAD-Weighted Gini (NEW!)\n",
    "\n",
    "For credit risk models, EAD weighting ensures larger exposures have more influence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, gini_weighted = plot_performance(\n",
    "    y_true=y_test,\n",
    "    y_pred=predictions[\"Logistic\"],\n",
    "    weights=ead_test,  # ← EAD weights\n",
    ")\n",
    "\n",
    "print(f\"Gini (EAD-weighted): {gini_weighted:.4f}\")\n",
    "print(f\"Difference: {gini_weighted - gini:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Multiple Models (NEW!)\n",
    "\n",
    "Plot all models on the same chart with automatic color assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, ginis = plot_performance(\n",
    "    y_true=y_test,\n",
    "    y_pred=[\n",
    "        predictions[\"Logistic\"],\n",
    "        predictions[\"Random Forest\"],\n",
    "        predictions[\"Gradient Boosting\"],\n",
    "    ],\n",
    "    labels=[\"Logistic\", \"Random Forest\", \"Gradient Boosting\"],\n",
    ")\n",
    "\n",
    "print(\"\\nModel Comparison (Unweighted):\")\n",
    "for name, g in zip([\"Logistic\", \"Random Forest\", \"Gradient Boosting\"], ginis):\n",
    "    print(f\"  {name:20s}: Gini = {g:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Custom Colormap (NEW!)\n",
    "\n",
    "Use custom colors for your models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom colors\n",
    "custom_colors = [\"#c430c1\", \"#ffa94d\", \"#55d3ed\"]\n",
    "\n",
    "fig, ax, ginis = plot_performance(\n",
    "    y_true=y_test,\n",
    "    y_pred=[\n",
    "        predictions[\"Logistic\"],\n",
    "        predictions[\"Random Forest\"],\n",
    "        predictions[\"Gradient Boosting\"],\n",
    "    ],\n",
    "    labels=[\"Logistic\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    colors=custom_colors,  # ← Custom colors\n",
    ")\n",
    "\n",
    "print(\"\\nCustom Colors Applied:\")\n",
    "for name, g, color in zip([\"Logistic\", \"Random Forest\", \"Gradient Boosting\"], ginis, custom_colors):\n",
    "    print(f\"  {name:20s}: Gini = {g:.4f} (color: {color})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiple Models with EAD Weighting\n",
    "\n",
    "Compare models using EAD-weighted Gini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, ginis_weighted = plot_performance(\n",
    "    y_true=y_test,\n",
    "    y_pred=[\n",
    "        predictions[\"Logistic\"],\n",
    "        predictions[\"Random Forest\"],\n",
    "        predictions[\"Gradient Boosting\"],\n",
    "    ],\n",
    "    weights=ead_test,  # ← EAD weights\n",
    "    labels=[\"Logistic\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    colors=custom_colors,\n",
    ")\n",
    "\n",
    "print(\"\\nModel Comparison (EAD-Weighted):\")\n",
    "for name, g in zip([\"Logistic\", \"Random Forest\", \"Gradient Boosting\"], ginis_weighted):\n",
    "    print(f\"  {name:20s}: Gini = {g:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Side-by-Side Comparison (NEW!)\n",
    "\n",
    "Create custom grid layouts to compare unweighted vs weighted Gini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1x2 grid\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Left: Unweighted\n",
    "_, _, ginis_unw = plot_performance(\n",
    "    y_test,\n",
    "    [\n",
    "        predictions[\"Logistic\"],\n",
    "        predictions[\"Random Forest\"],\n",
    "        predictions[\"Gradient Boosting\"],\n",
    "    ],\n",
    "    ax=ax1,\n",
    "    labels=[\"Logistic\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    colors=custom_colors,\n",
    ")\n",
    "ax1.set_title(\"Unweighted Gini\", fontsize=14)\n",
    "\n",
    "# Right: EAD-Weighted\n",
    "_, _, ginis_w = plot_performance(\n",
    "    y_test,\n",
    "    [\n",
    "        predictions[\"Logistic\"],\n",
    "        predictions[\"Random Forest\"],\n",
    "        predictions[\"Gradient Boosting\"],\n",
    "    ],\n",
    "    weights=ead_test,\n",
    "    ax=ax2,\n",
    "    labels=[\"Logistic\", \"Random Forest\", \"Gradient Boosting\"],\n",
    "    colors=custom_colors,\n",
    ")\n",
    "ax2.set_title(\"EAD-Weighted Gini\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSide-by-Side Comparison:\")\n",
    "print(f\"{'Model':<20s} {'Unweighted':>12s} {'EAD-Weighted':>12s} {'Difference':>12s}\")\n",
    "print(\"-\" * 60)\n",
    "for name, g_unw, g_w in zip([\"Logistic\", \"Random Forest\", \"Gradient Boosting\"], ginis_unw, ginis_w):\n",
    "    diff = g_w - g_unw\n",
    "    print(f\"{name:<20s} {g_unw:>12.4f} {g_w:>12.4f} {diff:>+12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Continuous Target - LGD Model (Beta)\n",
    "\n",
    "Demonstrates Power Curve for Loss Given Default (LGD) models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate continuous target (LGD)\n",
    "y_lgd = np.clip(\n",
    "    0.45 + 0.3 * df[\"debt_to_income\"] - 0.0002 * df[\"credit_score\"] + np.random.normal(0, 0.05, n),\n",
    "    0,\n",
    "    1,\n",
    ")\n",
    "\n",
    "# Split data\n",
    "X_train_lgd, X_test_lgd, y_train_lgd, y_test_lgd, ead_train_lgd, ead_test_lgd = train_test_split(\n",
    "    df, y_lgd, ead, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train LGD model\n",
    "model_lgd = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "model_lgd.fit(X_train_lgd, y_train_lgd)\n",
    "y_pred_lgd = model_lgd.predict(X_test_lgd)\n",
    "y_pred_lgd = np.clip(y_pred_lgd, 0, 1)\n",
    "\n",
    "print(f\"Mean LGD: {y_test_lgd.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 LGD Power Curve - Unweighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, gini_lgd = plot_performance(y_true=y_test_lgd, y_pred=y_pred_lgd)\n",
    "\n",
    "print(f\"LGD Gini (unweighted): {gini_lgd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 LGD Power Curve - EAD-Weighted (NEW!)\n",
    "\n",
    "For LGD models, EAD weighting is essential for Basel/regulatory compliance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, gini_lgd_weighted = plot_performance(\n",
    "    y_true=y_test_lgd,\n",
    "    y_pred=y_pred_lgd,\n",
    "    weights=ead_test_lgd,\n",
    ")\n",
    "\n",
    "print(f\"LGD Gini (EAD-weighted): {gini_lgd_weighted:.4f}\")\n",
    "print(f\"Difference: {gini_lgd_weighted - gini_lgd:+.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
